{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.009067</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>-0.005988</td>\n",
       "      <td>-0.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>0.004202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.006248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.027094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.285323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.028362</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>-0.009067</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.118533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.304180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.047820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>-0.011721</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.025651</td>\n",
       "      <td>0.085472</td>\n",
       "      <td>-0.028362</td>\n",
       "      <td>-0.010084</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>-0.156128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.005988</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.007201</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.011421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.027094</td>\n",
       "      <td>0.285323</td>\n",
       "      <td>-0.014001</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>-0.047820</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>-0.156128</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowNumber  CustomerId  CreditScore       Age    Tenure  \\\n",
       "RowNumber         1.000000    0.004202     0.005840  0.000783 -0.006495   \n",
       "CustomerId        0.004202    1.000000     0.005308  0.009497 -0.014883   \n",
       "CreditScore       0.005840    0.005308     1.000000 -0.003965  0.000842   \n",
       "Age               0.000783    0.009497    -0.003965  1.000000 -0.009997   \n",
       "Tenure           -0.006495   -0.014883     0.000842 -0.009997  1.000000   \n",
       "Balance          -0.009067   -0.012419     0.006268  0.028308 -0.012254   \n",
       "NumOfProducts     0.007246    0.016972     0.012238 -0.030680  0.013444   \n",
       "HasCrCard         0.000599   -0.014025    -0.005458 -0.011721  0.022583   \n",
       "IsActiveMember    0.012044    0.001665     0.025651  0.085472 -0.028362   \n",
       "EstimatedSalary  -0.005988    0.015271    -0.001384 -0.007201  0.007784   \n",
       "Exited           -0.016571   -0.006248    -0.027094  0.285323 -0.014001   \n",
       "\n",
       "                  Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber       -0.009067       0.007246   0.000599        0.012044   \n",
       "CustomerId      -0.012419       0.016972  -0.014025        0.001665   \n",
       "CreditScore      0.006268       0.012238  -0.005458        0.025651   \n",
       "Age              0.028308      -0.030680  -0.011721        0.085472   \n",
       "Tenure          -0.012254       0.013444   0.022583       -0.028362   \n",
       "Balance          1.000000      -0.304180  -0.014858       -0.010084   \n",
       "NumOfProducts   -0.304180       1.000000   0.003183        0.009612   \n",
       "HasCrCard       -0.014858       0.003183   1.000000       -0.011866   \n",
       "IsActiveMember  -0.010084       0.009612  -0.011866        1.000000   \n",
       "EstimatedSalary  0.012797       0.014204  -0.009933       -0.011421   \n",
       "Exited           0.118533      -0.047820  -0.007138       -0.156128   \n",
       "\n",
       "                 EstimatedSalary    Exited  \n",
       "RowNumber              -0.005988 -0.016571  \n",
       "CustomerId              0.015271 -0.006248  \n",
       "CreditScore            -0.001384 -0.027094  \n",
       "Age                    -0.007201  0.285323  \n",
       "Tenure                  0.007784 -0.014001  \n",
       "Balance                 0.012797  0.118533  \n",
       "NumOfProducts           0.014204 -0.047820  \n",
       "HasCrCard              -0.009933 -0.007138  \n",
       "IsActiveMember         -0.011421 -0.156128  \n",
       "EstimatedSalary         1.000000  0.012097  \n",
       "Exited                  0.012097  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels? (Total number of positive cases)\n",
    "data['Exited'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surname:\n",
      "2932\n",
      "['Hargrave' 'Hill' 'Onio' ... 'Kashiwagi' 'Aldridge' 'Burbidge']\n",
      "\n",
      "Geography:\n",
      "3\n",
      "['France' 'Spain' 'Germany']\n",
      "\n",
      "Gender:\n",
      "2\n",
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Number and names of categorical entries\n",
    "print(\"Surname:\")\n",
    "print(data['Surname'].nunique())\n",
    "print(data['Surname'].unique())\n",
    "print()\n",
    "print(\"Geography:\")\n",
    "print(data['Geography'].nunique())\n",
    "print(data['Geography'].unique())\n",
    "print()\n",
    "print(\"Gender:\")\n",
    "print(data['Gender'].nunique())\n",
    "print(data['Gender'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data transformation (make everything numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/db/7d8204ddba84ab5d1e4fd1af8f82bbe39c589488bee71e45c662f4144010/scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0MB 2.5MB/s eta 0:00:01     |███████████████████████▊        | 5.2MB 1.5MB/s eta 0:00:02     |█████████████████████████▍      | 5.6MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.4)\n",
      "Collecting joblib>=0.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1MB 2.4MB/s eta 0:00:01    |██▏                             | 1.7MB 1.9MB/s eta 0:00:13     |████████████████                | 13.0MB 7.1MB/s eta 0:00:02\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=d756263839ee983a10d18389a860e50ad28a645d6fe7578941c46957a3fdd4b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scipy, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.1 scipy-1.4.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    - Skipping first three features: RowNumber, CustomerId, Surname.\n",
    "    - Converting pandas dataframe to numpy array using .values\n",
    "\"\"\"\n",
    "X = data.iloc[:,3:13].values\n",
    "Y = data.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Germany', 'Spain'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode catagorical variables in col 2 and 3.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "country_encoder = LabelEncoder()\n",
    "X[:, 1] = country_encoder.fit_transform(X[:, 1])\n",
    "\n",
    "gender_encoder = LabelEncoder()\n",
    "X[:, 2] = gender_encoder.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 0, 0, 42, 2, 0.0, 1, 1, 1, 101348.88], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"OneHot\",        # Just a name\n",
    "         OneHotEncoder(), # The transformer class\n",
    "         [1]              # The column(s) to be applied on.\n",
    "         )\n",
    "    ],\n",
    "    remainder='passthrough' # donot apply anything to the remaining columns\n",
    ")\n",
    "X = transformer.fit_transform(X.tolist())\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 619, 0, 42, 2, 0.0, 1, 1, 1, 101348.88], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 1.0], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[:, 1])\n",
    "# Ques: is this correct, changing three classes to two?\n",
    "# Ques: What is one-hot encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bringing all the features to same scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 1: Using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Training the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Predict labels on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Performance metrics for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, accuracy):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt='.3f', linewidths=.5, square=True, cmap='Blues_r')\n",
    "    plt.xlabel('Predicted value')\n",
    "    plt.ylabel('Actual value')\n",
    "    header = f'Accuracy:{accuracy}'\n",
    "    plt.title(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 2: Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.17.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.27.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.17.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.34.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (45.1.0.post20200119)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install keras\n",
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.4838 - accuracy: 0.7958\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 0.4293 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 0.4241 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.4198 - accuracy: 0.8171\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4169 - accuracy: 0.8250\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 0.4148 - accuracy: 0.8282\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.4140 - accuracy: 0.8278\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.4123 - accuracy: 0.8299\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4112 - accuracy: 0.8320\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 0.4105 - accuracy: 0.8329\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 0.4097 - accuracy: 0.8334\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 170us/step - loss: 0.4091 - accuracy: 0.8330\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.4086 - accuracy: 0.8342\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 0.4078 - accuracy: 0.83220s - loss: 0.4047 - accuracy: 0.\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 0.4073 - accuracy: 0.8354\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.4071 - accuracy: 0.83390s\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 0.4066 - accuracy: 0.8325\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.4063 - accuracy: 0.8324\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4062 - accuracy: 0.8340\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 0.4054 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 0.4060 - accuracy: 0.8341\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4054 - accuracy: 0.8335\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 0.4051 - accuracy: 0.8331\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.4048 - accuracy: 0.8342\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.4045 - accuracy: 0.8356\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.4044 - accuracy: 0.8319\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4040 - accuracy: 0.8341\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.4043 - accuracy: 0.8345\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.4035 - accuracy: 0.8342\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.4039 - accuracy: 0.83240s - loss: 0.4034 - accuracy: 0.\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.4035 - accuracy: 0.8332\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.4034 - accuracy: 0.8330\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.4031 - accuracy: 0.8326\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.4035 - accuracy: 0.8335\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.4030 - accuracy: 0.8345\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.4026 - accuracy: 0.8334\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 0.4030 - accuracy: 0.8331\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 0.4025 - accuracy: 0.8335\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4023 - accuracy: 0.8319\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 0.4022 - accuracy: 0.8339\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 0.4018 - accuracy: 0.8332\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 0.4021 - accuracy: 0.8340\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 0.4023 - accuracy: 0.8338\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 175us/step - loss: 0.4021 - accuracy: 0.8331\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.4021 - accuracy: 0.8338\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 0.4018 - accuracy: 0.8349\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.4020 - accuracy: 0.8330\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4011 - accuracy: 0.8331\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.4019 - accuracy: 0.8336\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 0.4019 - accuracy: 0.8345\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 0.4014 - accuracy: 0.8325\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 188us/step - loss: 0.4013 - accuracy: 0.8342\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 0.4010 - accuracy: 0.8345\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 242us/step - loss: 0.4011 - accuracy: 0.8339\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4004 - accuracy: 0.8353\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 289us/step - loss: 0.4011 - accuracy: 0.8334\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 181us/step - loss: 0.4003 - accuracy: 0.8342\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 181us/step - loss: 0.4008 - accuracy: 0.8370\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.4005 - accuracy: 0.8341\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 0.4002 - accuracy: 0.8339\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 0.4000 - accuracy: 0.8340\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.4001 - accuracy: 0.8361\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 0.4001 - accuracy: 0.8356\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 0.4001 - accuracy: 0.8354\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.4005 - accuracy: 0.8347\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3997 - accuracy: 0.8354\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 0.4001 - accuracy: 0.8349\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3992 - accuracy: 0.8366\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.4003 - accuracy: 0.8331\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 0.3998 - accuracy: 0.8364\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 0.4002 - accuracy: 0.8365\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 0.3995 - accuracy: 0.8340\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 0.3994 - accuracy: 0.8340\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.3997 - accuracy: 0.8370\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 0.4001 - accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 0.3996 - accuracy: 0.8350\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 0.3999 - accuracy: 0.8357\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 0.3995 - accuracy: 0.8370\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 0.4000 - accuracy: 0.8356\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 0.3995 - accuracy: 0.8346\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3991 - accuracy: 0.8357\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.3996 - accuracy: 0.8356\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.3999 - accuracy: 0.8346\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 0.4000 - accuracy: 0.8365\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 0.3993 - accuracy: 0.8367\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 0.3995 - accuracy: 0.8359\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 0.3995 - accuracy: 0.8357\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.3994 - accuracy: 0.8360\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.3995 - accuracy: 0.8355\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 0.3996 - accuracy: 0.8342\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.3991 - accuracy: 0.8364\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3997 - accuracy: 0.8346\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 0.3993 - accuracy: 0.8355\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.3996 - accuracy: 0.8342\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 0.3996 - accuracy: 0.8353\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.3994 - accuracy: 0.8356\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 0.3995 - accuracy: 0.8354\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 0.3996 - accuracy: 0.8341\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 181us/step - loss: 0.3993 - accuracy: 0.8363\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 171us/step - loss: 0.3995 - accuracy: 0.8357\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(x_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8328"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_hist = history.history['accuracy']\n",
    "accuracy = round(sum(acc_hist)/len(acc_hist), 4)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1528   67]\n",
      " [ 257  148]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy\n",
    "accuracy = (cm[0][0] + cm[1][1])/cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\"\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "new_prediction = (new_prediction > 0.5)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to answer:\n",
    "1. What is one-hot encoding?\n",
    "2. How does ML logistic regression work?\n",
    "3. In deep learning implementations:\n",
    "    - Explain binary_crossentropy\n",
    "    - Explain adam optimizer\n",
    "    - Relu function\n",
    "    - Sigmoid function\n",
    "    - Difference between model.compile() and model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 2: Using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the categorical values (Geography, Gender) should be converted into dummy variables.\n",
    "dataset_df = pd.get_dummies(dataset_df)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[619.,  42.,   2., ...,   0.,   1.,   0.],\n",
       "        [608.,  41.,   1., ...,   1.,   1.,   0.],\n",
       "        [502.,  42.,   8., ...,   0.,   1.,   0.],\n",
       "        ...,\n",
       "        [709.,  36.,   7., ...,   0.,   1.,   0.],\n",
       "        [772.,  42.,   3., ...,   0.,   0.,   1.],\n",
       "        [792.,  28.,   4., ...,   0.,   1.,   0.]]),\n",
       " ['CreditScore',\n",
       "  'Age',\n",
       "  'Tenure',\n",
       "  'Balance',\n",
       "  'NumOfProducts',\n",
       "  'HasCrCard',\n",
       "  'IsActiveMember',\n",
       "  'EstimatedSalary',\n",
       "  'Geography_France',\n",
       "  'Geography_Germany',\n",
       "  'Geography_Spain',\n",
       "  'Gender_Female',\n",
       "  'Gender_Male'],\n",
       " array([1, 0, 1, ..., 1, 1, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With all data converted to numerical values, it's time to put them into a matrix!\n",
    "features = np.array(dataset_df.drop('Exited', axis=1))\n",
    "feature_names = dataset_df.drop('Exited', axis=1).columns.tolist()\n",
    "labels = np.array(dataset_df['Exited'])\n",
    "features, feature_names, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142,  0.29351742, -1.04175968, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-0.44003595,  0.19816383, -1.38753759, ...,  1.74273971,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-1.53679418,  0.29351742,  1.03290776, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       ...,\n",
       "       [ 0.60498839, -0.27860412,  0.68712986, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 1.25683526,  0.29351742, -0.69598177, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [ 1.46377078, -1.04143285, -0.35020386, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the range of values are inconsistent over different features, it should be normalized.\n",
    "features = (features - features.mean(axis=0, keepdims=True)) / features.std(axis=0, keepdims=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting torch\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 13.7 MB/s eta 0:00:01  |▎                               | 7.0 MB 1.3 MB/s eta 0:09:39     |▎                               | 7.2 MB 1.3 MB/s eta 0:09:39     |▌                               | 10.6 MB 1.3 MB/s eta 0:09:26     |▌                               | 12.0 MB 1.3 MB/s eta 0:09:25     |▋                               | 15.4 MB 1.3 MB/s eta 0:09:22     |▉                               | 19.0 MB 1.3 MB/s eta 0:09:19[K     |█                               | 26.0 MB 2.4 MB/s eta 0:05:02     |█▋                              | 37.0 MB 5.4 MB/s eta 0:02:13     |██▏                             | 51.6 MB 2.3 MB/s eta 0:05:03     |██▊                             | 64.2 MB 4.7 MB/s eta 0:02:28     |███                             | 71.5 MB 3.6 MB/s eta 0:03:09     |███                             | 72.0 MB 2.1 MB/s eta 0:05:23     |███▏                            | 74.5 MB 2.1 MB/s eta 0:05:22     |███▏                            | 75.6 MB 2.1 MB/s eta 0:05:21     |███▋                            | 85.2 MB 8.9 MB/s eta 0:01:15     |████▋                           | 108.5 MB 8.4 MB/s eta 0:01:17     |████▋                           | 109.4 MB 8.4 MB/s eta 0:01:17     |████▊                           | 110.3 MB 8.4 MB/s eta 0:01:17 |████▊                           | 110.7 MB 8.4 MB/s eta 0:01:17     |████▊                           | 111.1 MB 8.4 MB/s eta 0:01:17     |████▉                           | 113.2 MB 1.1 MB/s eta 0:09:57     |█████▏                          | 120.7 MB 16.1 MB/s eta 0:00:40     |██████▏                         | 144.5 MB 14.6 MB/s eta 0:00:42     |██████▉                         | 161.8 MB 6.0 MB/s eta 0:01:40     |██████▉                         | 162.0 MB 6.0 MB/s eta 0:01:40     |███████▉                        | 183.7 MB 14.6 MB/s eta 0:00:39     |████████▏                       | 191.1 MB 6.9 MB/s eta 0:01:22     |█████████▎                      | 218.6 MB 23.6 MB/s eta 0:00:23     |█████████▎                      | 219.2 MB 23.6 MB/s eta 0:00:23     |██████████                      | 237.7 MB 14.7 MB/s eta 0:00:36     |████████████▍                   | 292.9 MB 9.2 MB/s eta 0:00:51��████████▌                   | 295.4 MB 6.9 MB/s eta 0:01:06     |████████████▋                   | 295.8 MB 6.9 MB/s eta 0:01:06     |█████████████▋                  | 321.6 MB 19.8 MB/s eta 0:00:22     |█████████████▊                  | 322.1 MB 19.8 MB/s eta 0:00:22     |█████████████▉                  | 325.4 MB 19.8 MB/s eta 0:00:22     |██████████████▍                 | 338.4 MB 6.3 MB/s eta 0:01:07     |███████████████                 | 352.0 MB 25.8 MB/s eta 0:00:16     |███████████████▊                | 369.9 MB 31.1 MB/s eta 0:00:13     |████████████████▎               | 382.1 MB 10.3 MB/s eta 0:00:36     |█████████████████               | 402.5 MB 13.9 MB/s eta 0:00:26     |██████████████████              | 421.3 MB 5.0 MB/s eta 0:01:07     |██████████████████▎             | 430.9 MB 16.5 MB/s eta 0:00:20     |██████████████████▎             | 431.1 MB 16.5 MB/s eta 0:00:20MB/s eta 0:00:20     |██████████████████▍             | 431.7 MB 16.5 MB/s eta 0:00:20     |██████████████████▌             | 434.3 MB 1.9 MB/s eta 0:02:52     |██████████████████▊             | 439.5 MB 658 kB/s eta 0:07:57     |███████████████████▏            | 452.4 MB 2.7 MB/s eta 0:01:50     |███████████████████▎            | 454.6 MB 2.7 MB/s eta 0:01:49     |███████████████████▌            | 459.4 MB 9.8 MB/s eta 0:00:31     |████████████████████▎           | 476.1 MB 17.0 MB/s eta 0:00:17     |████████████████████▍           | 479.8 MB 22.2 MB/s eta 0:00:13     |████████████████████▋           | 486.2 MB 22.2 MB/s eta 0:00:13�████████▉           | 489.4 MB 3.1 MB/s eta 0:01:26     |████████████████████▉           | 491.7 MB 3.1 MB/s eta 0:01:25     |█████████████████████           | 496.4 MB 5.5 MB/s eta 0:00:48     |█████████████████████▍          | 502.4 MB 13.0 MB/s eta 0:00:20:00:19     |█████████████████████▊          | 511.1 MB 13.0 MB/s eta 0:00:19     |██████████████████████          | 518.6 MB 13.2 MB/s eta 0:00:18     |██████████████████████▎         | 523.3 MB 7.5 MB/s eta 0:00:31     |██████████████████████▉         | 537.1 MB 6.4 MB/s eta 0:00:34     |███████████████████████         | 543.4 MB 21.5 MB/s eta 0:00:10�██████████▎        | 549.2 MB 21.5 MB/s eta 0:00:10     |███████████████████████▊        | 558.0 MB 3.4 MB/s eta 0:00:58     |███████████████████████▉        | 562.3 MB 22.4 MB/s eta 0:00:09     |████████████████████████▎       | 571.1 MB 22.4 MB/s eta 0:00:09     |████████████████████████▌       | 576.8 MB 10.9 MB/s eta 0:00:17     |██████████████████████████▍     | 621.2 MB 7.3 MB/s eta 0:00:19     |██████████████████████████▊     | 628.2 MB 7.3 MB/s eta 0:00:18     |███████████████████████████     | 635.1 MB 5.5 MB/s eta 0:00:22�████████▍    | 644.7 MB 7.2 MB/s eta 0:00:16████████▍    | 645.1 MB 7.2 MB/s eta 0:00:15     |████████████████████████████▋   | 673.7 MB 9.1 MB/s eta 0:00:09     |█████████████████████████████   | 680.2 MB 9.1 MB/s eta 0:00:09     |█████████████████████████████   | 681.6 MB 27.5 MB/s eta 0:00:03     |█████████████████████████████   | 683.6 MB 27.5 MB/s eta 0:00:03     |█████████████████████████████   | 684.5 MB 27.5 MB/s eta 0:00:03     |██████████████████████████████  | 704.0 MB 6.7 MB/s eta 0:00:08     |██████████████████████████████  | 706.2 MB 6.7 MB/s eta 0:00:08     |██████████████████████████████  | 707.6 MB 6.7 MB/s eta 0:00:07     |██████████████████████████████▉ | 724.7 MB 3.5 MB/s eta 0:00:09     |███████████████████████████████▉| 750.4 MB 13.7 MB/s eta 0:00:01     |████████████████████████████████| 752.0 MB 13.7 MB/s eta 0:00:01Killed\n"
     ]
    }
   ],
   "source": [
    "! pip install torch --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.17.5)\n",
      "Collecting torch==1.4.0\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 11.9 MB/s eta 0:00:01  |▏                               | 3.2 MB 2.8 MB/s eta 0:04:28     |▊                               | 16.1 MB 16.2 MB/s eta 0:00:46     |▊                               | 17.3 MB 16.2 MB/s eta 0:00:46     |█▊                              | 40.6 MB 27.5 MB/s eta 0:00:26     |██▍                             | 55.3 MB 8.9 MB/s eta 0:01:19     |██▊                             | 62.9 MB 3.2 MB/s eta 0:03:38     |██▉                             | 67.5 MB 3.2 MB/s eta 0:03:37     |███▉                            | 91.4 MB 6.5 MB/s eta 0:01:43     |████▏                           | 98.9 MB 6.5 MB/s eta 0:01:41     |████▍                           | 102.8 MB 20.4 MB/s eta 0:00:32     |█████                           | 120.2 MB 3.5 MB/s eta 0:03:01     |█████▎                          | 123.0 MB 3.5 MB/s eta 0:03:00     |█████▉                          | 138.5 MB 1.4 MB/s eta 0:07:27     |██████▎                         | 148.0 MB 1.2 MB/s eta 0:08:34     |███████                         | 163.4 MB 1.3 MB/s eta 0:07:43     |███████▎                        | 170.2 MB 1.3 MB/s eta 0:07:38     |███████▊                        | 182.0 MB 5.4 MB/s eta 0:01:46     |████████▎                       | 193.7 MB 40.5 MB/s eta 0:00:14MB 16.5 MB/s eta 0:00:33     |█████████                       | 212.2 MB 3.8 MB/s eta 0:02:25     |█████████▍                      | 221.8 MB 3.8 MB/s eta 0:02:22     |█████████▌                      | 223.1 MB 3.8 MB/s eta 0:02:22     |█████████▋                      | 227.3 MB 3.4 MB/s eta 0:02:37     |██████████                      | 236.5 MB 3.4 MB/s eta 0:02:34     |██████████▏                     | 239.2 MB 3.5 MB/s eta 0:02:26     |██████████▍                     | 244.6 MB 3.5 MB/s eta 0:02:24     |██████████▍                     | 244.7 MB 3.5 MB/s eta 0:02:24     |██████████▌                     | 246.4 MB 3.5 MB/s eta 0:02:23     |███████████                     | 256.8 MB 3.9 MB/s eta 0:02:08     |███████████▌                    | 270.7 MB 1.5 MB/s eta 0:05:22     |████████████                    | 282.9 MB 1.9 MB/s eta 0:04:08     |████████████▏                   | 286.1 MB 1.9 MB/s eta 0:04:07��████████▊                   | 299.8 MB 4.8 MB/s eta 0:01:35     |█████████████                   | 306.6 MB 3.2 MB/s eta 0:02:223.2 MB/s eta 0:02:19     |██████████████                  | 331.3 MB 4.3 MB/s eta 0:01:40     |███████████████▍                | 363.2 MB 7.9 MB/s eta 0:00:50     |████████████████                | 374.4 MB 2.0 MB/s eta 0:03:14     |████████████████                | 375.7 MB 2.0 MB/s eta 0:03:13  | 397.0 MB 3.8 MB/s eta 0:01:35     |█████████████████               | 397.9 MB 3.8 MB/s eta 0:01:35     |█████████████████               | 401.9 MB 3.8 MB/s eta 0:01:34     |█████████████████▍              | 408.1 MB 5.4 MB/s eta 0:01:04     |█████████████████▍              | 410.3 MB 5.4 MB/s eta 0:01:04     |█████████████████▉              | 418.6 MB 2.0 MB/s eta 0:02:51     |██████████████████▏             | 427.6 MB 2.0 MB/s eta 0:02:47     |██████████████████▍             | 434.0 MB 1.8 MB/s eta 0:02:57     |███████████████████▌            | 460.3 MB 5.6 MB/s eta 0:00:53     |████████████████████▏           | 474.7 MB 2.1 MB/s eta 0:02:13     |████████████████████▋           | 484.1 MB 3.0 MB/s eta 0:01:30     |████████████████████▊           | 487.2 MB 3.0 MB/s eta 0:01:29     |████████████████████▉           | 490.5 MB 2.2 MB/s eta 0:02:00     |████████████████████▉           | 491.3 MB 2.2 MB/s eta 0:02:00     |█████████████████████▎          | 500.1 MB 2.2 MB/s eta 0:01:56     |█████████████████████▎          | 500.4 MB 2.2 MB/s eta 0:01:56     |█████████████████████▍          | 504.4 MB 4.3 MB/s eta 0:00:59     |█████████████████████▌          | 505.0 MB 4.3 MB/s eta 0:00:59     |█████████████████████▉          | 512.8 MB 4.3 MB/s eta 0:00:57��█████████████████████          | 517.7 MB 1.8 MB/s eta 0:02:14     |██████████████████████▏         | 522.9 MB 1.8 MB/s eta 0:02:11     |██████████████████████▏         | 523.1 MB 1.8 MB/s eta 0:02:11     |███████████████████████         | 541.7 MB 2.5 MB/s eta 0:01:25     |███████████████████████▋        | 556.8 MB 5.2 MB/s eta 0:00:38     |███████████████████████▋        | 557.0 MB 5.2 MB/s eta 0:00:38     |███████████████████████▉        | 560.5 MB 5.2 MB/s eta 0:00:38     |████████████████████████▎       | 572.6 MB 2.8 MB/s eta 0:01:04��████████████████▋       | 579.7 MB 7.2 MB/s eta 0:00:25     |█████████████████████████▍      | 598.8 MB 1.6 MB/s eta 0:01:39     |█████████████████████████▌      | 600.8 MB 1.6 MB/s eta 0:01:37     |█████████████████████████▉      | 608.1 MB 4.3 MB/s eta 0:00:34     |██████████████████████████▍     | 620.9 MB 1.5 MB/s eta 0:01:27     |██████████████████████████▍     | 621.7 MB 1.5 MB/s eta 0:01:26     |██████████████████████████▍     | 622.1 MB 1.5 MB/s eta 0:01:26     |███████████████████████████     | 633.6 MB 17.0 MB/s eta 0:00:08     |███████████████████████████▍    | 644.2 MB 18.4 MB/s eta 0:00:06��█████████████▋    | 649.8 MB 18.4 MB/s eta 0:00:06     |███████████████████████████▉    | 654.8 MB 4.0 MB/s eta 0:00:25.0 MB 4.0 MB/s eta 0:00:23��███████████████████▌   | 671.0 MB 2.4 MB/s eta 0:00:35     |████████████████████████████▌   | 671.4 MB 2.4 MB/s eta 0:00:34     |█████████████████████████████   | 682.5 MB 9.6 MB/s eta 0:00:08     |█████████████████████████████▏  | 685.4 MB 9.6 MB/s eta 0:00:08     |█████████████████████████████▎  | 688.5 MB 1.8 MB/s eta 0:00:37     |██████████████████████████████  | 706.0 MB 4.7 MB/s eta 0:00:11     |██████████████████████████████▏ | 710.1 MB 4.7 MB/s eta 0:00:10     |██████████████████████████████▋ | 719.8 MB 7.1 MB/s eta 0:00:05     |██████████████████████████████▊ | 722.6 MB 7.1 MB/s eta 0:00:058 MB 7.1 MB/s eta 0:00:045 MB 7.9 MB/s eta 0:00:039 MB 7.9 MB/s eta 0:00:03██████ | 732.0 MB 7.9 MB/s eta 0:00:03B 7.9 MB/s eta 0:00:03�██████████████▏| 733.1 MB 7.9 MB/s eta 0:00:03Killed\n"
     ]
    }
   ],
   "source": [
    "! pip install torchvision --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-36e06aa5cc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
